{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download audio from Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pytube\n",
    "%pip install pydub\n",
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "import os\n",
    "import math \n",
    "from pydub import AudioSegment\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_audio_from_youtube(yt_url):\n",
    "    yt = YouTube(yt_url)\n",
    "    return yt.streams.filter(only_audio=True).first().download()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp4_file = download_audio_from_youtube(\"https://www.youtube.com/watch?v=VHYg1P8lA9o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_audio_data(mp4_file, min_per_split):\n",
    "    song = AudioSegment.from_file(mp4_file, \"mp4\")\n",
    "\n",
    "    path = os.path.splitext(mp4_file)[0]\n",
    "    \n",
    "    try: \n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "    except OSError as error: \n",
    "        print(error)\n",
    "    \n",
    "    total_mins = math.ceil(song.duration_seconds / 60)\n",
    "    \n",
    "    for i in range(0, total_mins, min_per_split):\n",
    "        file_to_export = os.path.join(path, f\"{os.path.splitext(mp4_file)[0]}_{int(i / min_per_split + 1)}.mp4\")\n",
    "        from_min = i * 60 * 1000\n",
    "        to_min = (i + min_per_split) * 60 * 1000\n",
    "        split_audio = song[from_min:to_min]\n",
    "        split_audio.export(file_to_export, format=\"mp4\")\n",
    "        print(f\"Created: {file_to_export}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Spliting all audio from mp4 video each 10 minutes to send it to Open AI API for transcribing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_audio_data(os.path.basename(mp4_file), min_per_split = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcribe audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audios_from_folder_path(folder_path):  \n",
    "    files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "    client = OpenAI(\n",
    "        api_key=OPENAI_API_KEY\n",
    "    )\n",
    "\n",
    "    transcription_path = os.path.join(folder_path, \"transcriptions\")\n",
    "    try: \n",
    "        if not os.path.exists(transcription_path):\n",
    "            os.mkdir(transcription_path)\n",
    "    except OSError as error: \n",
    "        print(error)\n",
    "\n",
    "    for file in files:\n",
    "        try:\n",
    "            with open(os.path.join(folder_path, file), \"rb\") as audio_file:\n",
    "                transcript = client.audio.transcriptions.create(\n",
    "                    model = \"whisper-1\", \n",
    "                    file = audio_file \n",
    "                )\n",
    "            \n",
    "            with open(os.path.join(folder_path, \"transcriptions\", f\"{os.path.splitext(file)[0]}.txt\"), 'w') as f:\n",
    "                f.write(transcript.text)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "def join_transcriptions(folder_path):\n",
    "    files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "    file_name = os.path.splitext(files[0])[0].split(\"_\")[0]\n",
    "    \n",
    "    transcriptions = []\n",
    "    for file in files:\n",
    "        with open(os.path.join(folder_path, file), \"r\") as f:\n",
    "            contents = f.read()\n",
    "            transcriptions.append(contents)\n",
    "    \n",
    "    with open(os.path.join(folder_path, f\"{file_name}_full.txt\"), 'w') as f:\n",
    "        f.write(\" \".join(transcriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp4_file = \"Antonio Escohotado en diálogo con Ernesto Castro.mp4\"\n",
    "\n",
    "path = f\"{os.path.splitext(mp4_file)[0]}\\\\\"\n",
    "\n",
    "transcribe_audios_from_folder_path(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join all transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp4_file = \"Antonio Escohotado en diálogo con Ernesto Castro.mp4\"\n",
    "\n",
    "path = f\"{os.path.splitext(mp4_file)[0]}\\\\\"\n",
    "path = os.path.join(path, \"transcriptions\")\n",
    "\n",
    "join_transcriptions(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat GPT processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp4_file = \"Antonio Escohotado en diálogo con Ernesto Castro.mp4\"\n",
    "\n",
    "suffix_file_name = os.path.splitext(mp4_file)[0]\n",
    "path = f\"{suffix_file_name}\\\\\"\n",
    "text_file = os.path.join(path, \"transcriptions\", \"Antonio Escohotado en diálogo con Ernesto Castro_full.txt\")\n",
    "\n",
    "f = open(text_file, \"r\")\n",
    "text_contents = f.read()\n",
    "f.close()\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"\"\"\n",
    "            You are a helpful assistant.\n",
    "            Given an interview provided by the user delimited by triple backticks, \n",
    "            your task is to create a detailed and concise summary of an interview, \n",
    "            highlighting the key points, opinions and perspectives of the interviewee, \n",
    "            important quotes, relevant context and background information, conclusions of the interviewer, \n",
    "            and any significant additional comments or reactions.\n",
    "        \"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"```{text_contents}```\"}\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response_message = response.choices[0].message.content\n",
    "print(response_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path, \"transcriptions\", \"Antonio Escohotado en diálogo con Ernesto Castro_result.txt\"), 'w') as f:\n",
    "    f.write(response_message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
